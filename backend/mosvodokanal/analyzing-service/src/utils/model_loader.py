import os
import aiohttp
import asyncio
from utils.logger import get_logger

logger = get_logger(__name__)

async def download_models():
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª–∏ –∏–∑ S3 –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"""
    models_dir = "prediction/models"
    os.makedirs(models_dir, exist_ok=True)
    
    # URL'—ã –º–æ–¥–µ–ª–µ–π
    model_urls = {
        'sarimax_model_gvs_podacha.pkl': 'https://storage.yandexcloud.net/wedrochers/sarimax_model_gvs_podacha.pkl',
        'sarimax_model_gvs_obratka.pkl': 'https://storage.yandexcloud.net/wedrochers/sarimax_model_gvs_obratka.pkl',
        'sarimax_model_xvs.pkl': 'https://storage.yandexcloud.net/wedrochers/sarimax_model_xvs.pkl'
    }
    
    logger.info("üì• Downloading models from S3...")
    
    timeout = aiohttp.ClientTimeout(total=300)  # 5 –º–∏–Ω—É—Ç
    async with aiohttp.ClientSession(timeout=timeout) as session:
        
        for filename, url in model_urls.items():
            file_path = os.path.join(models_dir, filename)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
            if os.path.exists(file_path):
                logger.info(f"‚úÖ Model {filename} already exists, skipping")
                continue
            
            try:
                logger.info(f"‚¨áÔ∏è Downloading {filename}...")
                
                async with session.get(url) as response:
                    if response.status == 200:
                        with open(file_path, 'wb') as f:
                            async for chunk in response.content.iter_chunked(8192):
                                f.write(chunk)
                        
                        file_size = os.path.getsize(file_path)
                        logger.info(f"‚úÖ Downloaded {filename}: {file_size} bytes")
                    else:
                        logger.error(f"‚ùå Failed to download {filename}: HTTP {response.status}")
                        
            except Exception as e:
                logger.error(f"‚ùå Error downloading {filename}: {e}")
                if os.path.exists(file_path):
                    os.remove(file_path)  # –£–¥–∞–ª—è–µ–º —á–∞—Å—Ç–∏—á–Ω–æ —Å–∫–∞—á–∞–Ω–Ω—ã–π —Ñ–∞–π–ª
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –º–æ–¥–µ–ª–∏ —Å–∫–∞—á–∞–ª–∏—Å—å
    downloaded_models = []
    for filename in model_urls.keys():
        file_path = os.path.join(models_dir, filename)
        if os.path.exists(file_path):
            downloaded_models.append(filename)
    
    logger.info(f"üìä Downloaded models: {len(downloaded_models)}/{len(model_urls)}")
    
    if len(downloaded_models) == len(model_urls):
        logger.info("üéâ All models downloaded successfully!")
    else:
        logger.warning(f"‚ö†Ô∏è Only {len(downloaded_models)} models downloaded")
    
    return {filename: os.path.join(models_dir, filename) 
            for filename in downloaded_models}